{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet Rio Chip Classification Data Prep\n",
    "\n",
    "This notebook prepares data for training a chip classification model on the Rio SpaceNet dataset.\n",
    "\n",
    "* Set `raw_uri` to the local or S3 directory containing the raw dataset.\n",
    "* Set `processed_uri` to a local or S3 directory (you can write to), which will store the processed data generated by this notebook.\n",
    "\n",
    "This is all you will need to do in order to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_uri = 's3://spacenet-dataset/'\n",
    "processed_uri = '/opt/data/examples/spacenet/rio/processed-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps we'll take to make the data are as follows:\n",
    "\n",
    "- Get the building labels and AOI (most likely from the SpaceNet AWS public dataset bucket)\n",
    "- Use the AOI and the image bounds to determine which images can be used for training and validation\n",
    "- Split the building labels by image, save a label GeoJSON file per image\n",
    "- Split the labeled images into a training and validation set, using the percentage of the AOI each covers, aiming at an 80%/20% split.\n",
    "\n",
    "This process will save the split label files, and `train_scenes.csv` and `val_scenes.csv` files that are used by the experiment at `examples/chip_classification/spacenet_rio.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import rasterio\n",
    "from shapely.geometry import (Polygon, shape)\n",
    "\n",
    "from rastervision.pipeline.file_system import (\n",
    "    download_if_needed, list_paths, file_to_json, json_to_file, \n",
    "    get_local_path, make_dir, sync_to_dir, str_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the label and AOI data from AWS's public dataset of Space Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_uri = join(raw_uri, 'AOIs/AOI_1_Rio/srcData/buildingLabels/Rio_Buildings_Public_AOI_v2.geojson')\n",
    "aoi_uri = join(raw_uri, 'AOIs/AOI_1_Rio/srcData/buildingLabels/Rio_OUTLINE_Public_AOI.geojson')\n",
    "\n",
    "label_json = file_to_json(label_uri)\n",
    "aoi_json = file_to_json(aoi_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the AOI to determine what images are inside the training set\n",
    "\n",
    "Here we compare the AOI to the image extents to deteremine which images we can use for training and validation. We're using `rasterio`'s ability to read the metadata from raster data on S3 without downloading the whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = shape(aoi_json['features'][0]['geometry'])\n",
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_uri = join(raw_uri, 'AOIs/AOI_1_Rio/srcData/mosaic_3band')\n",
    "image_paths = list_paths(images_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_to_shape(bounds):\n",
    "    return Polygon([[bounds.left, bounds.bottom],\n",
    "                    [bounds.left, bounds.top],\n",
    "                    [bounds.right, bounds.top],\n",
    "                    [bounds.right, bounds.bottom],\n",
    "                    [bounds.left, bounds.bottom]])\n",
    "\n",
    "image_to_extents = {}\n",
    "for img in image_paths:\n",
    "    with rasterio.open(img, 'r') as ds:\n",
    "        image_to_extents[img] = bounds_to_shape(ds.bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting_images = []\n",
    "for img in image_to_extents:\n",
    "    if image_to_extents[img].intersects(aoi):\n",
    "        intersecting_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match labels to images\n",
    "\n",
    "Find the labels that intersect with the image's bounding box, which will be saved into a labels geojson that matches the image name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a class_id and class_name to the properties of each feature\n",
    "for feature in label_json['features']:\n",
    "    feature['properties']['class_id'] = 1\n",
    "    feature['properties']['class_name'] = 'building'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_features = {}\n",
    "for img in intersecting_images:\n",
    "    image_to_features[img] = []\n",
    "    bbox = image_to_extents[img]\n",
    "    for feature in label_json['features']:\n",
    "        if shape(feature['geometry']).intersects(bbox):\n",
    "            image_to_features[img].append(feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_labels_uri = join(processed_uri, 'labels')\n",
    "\n",
    "for img in image_to_features:\n",
    "    fc = {}\n",
    "    fc['type'] = 'FeatureCollection'\n",
    "    fc['crs'] = label_json['crs']\n",
    "    fc['features'] = image_to_features[img]\n",
    "    img_id = os.path.splitext(os.path.basename(img))[0]\n",
    "    label_path = join(processed_labels_uri, '{}.geojson'.format(img_id))\n",
    "    json_to_file(fc, label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation\n",
    "\n",
    "Split up training and validation data. There's an odd shaped AOI and not that many images, so we'll split the train and validation roughly based on how much area each scene covers of the AOI. \n",
    "\n",
    "Create a CSV that our experiments will use to load the training and validation data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and validation\n",
    "ratio = 0.8\n",
    "aoi_area = aoi.area\n",
    "images_to_area = {}\n",
    "for img in intersecting_images:\n",
    "    area = image_to_extents[img].intersection(aoi).area\n",
    "    images_to_area[img] = area / aoi_area\n",
    "\n",
    "train_imgs = []\n",
    "val_imgs = []\n",
    "train_area_covered = 0\n",
    "for img in sorted(intersecting_images, reverse=True, key=lambda img: images_to_area[img]):\n",
    "    if train_area_covered < ratio:\n",
    "        train_imgs.append(img)\n",
    "        train_area_covered += images_to_area[img]\n",
    "    else:\n",
    "        val_imgs.append(img)\n",
    "print(\"{} training images with {}% area.\".format(len(train_imgs), train_area_covered))\n",
    "print(\"{} validation images with {} area.\".format(len(val_imgs), 1 - train_area_covered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split_csv(imgs, path):\n",
    "    csv_rows = []\n",
    "    for img in imgs:\n",
    "        img_id = os.path.splitext(os.path.basename(img))[0]\n",
    "        img_path = join('AOIs', 'AOI_1_Rio', 'srcData/mosaic_3band', '{}.tif'.format(img_id))\n",
    "        label_path = join('labels','{}.geojson'.format(img_id))\n",
    "        csv_rows.append('\"{}\",\"{}\"'.format(img_path, label_path))\n",
    "    str_to_file('\\n'.join(csv_rows), path)\n",
    "        \n",
    "save_split_csv(train_imgs, join(processed_uri, 'train-scenes.csv'))\n",
    "save_split_csv(val_imgs, join(processed_uri, 'val-scenes.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
